{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U-Net_Architecture.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXqPA_sZceg5",
        "colab_type": "text"
      },
      "source": [
        "### **U-net architecture**\n",
        "\n",
        "Developing the Model (UNet) Using Keras Functional API\n",
        "\n",
        "For this example, we are going to implement a popular architecture: UNet. In a sense, it is not the best for a titorial since this model is very heavy. But I found the exercise interesting. Especially because we are going to use the functional API provided by keras.\n",
        "\n",
        "This architecture was introduce in the paper **U-Net: Convolutional Networks for Biomedical Image Segmentation** that you can read there: https://arxiv.org/abs/1505.04597  \n",
        "\n",
        "You can also read my notes on this paper there: https://yann-leguilly.gitlab.io/post/2019-12-11-unet-biomedical-images/   \n",
        "Basically we are going to reproduce this:  \n",
        "\n",
        "\n",
        "<p align=\"center\"><img src=\"https://yann-leguilly.gitlab.io/img/unet_1/figure_1.png\" width=\"60%\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RTNfapMNJHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ARkFS1xlaVax"
      },
      "source": [
        "#### **Load ResNet50**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ve6ZdPjbN6P",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<p align=\"center\"><img src=\"https://i.stack.imgur.com/gI4zT.png\" width=\"60%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PpzTJn7aRae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.applications.ResNet50(weights=\"imagenet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Wd1mVl5beD8"
      },
      "source": [
        "#### **Model summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YggO4zZ_abci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc0774b0-64b4-4275-b8c7-1247388d71dd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 25,636,712\n",
            "Trainable params: 25,583,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2GTBBDKctEB",
        "colab_type": "text"
      },
      "source": [
        "### **VGG-16**\n",
        "\n",
        "<p align=\"center\"><img src=\"https://www.researchgate.net/profile/Max_Ferguson/publication/322512435/figure/fig3/AS:697390994567179@1543282378794/Fig-A1-The-standard-VGG-16-network-architecture-as-proposed-in-32-Note-that-only.png\" width=\"60%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6IQqkLkYL41",
        "colab_type": "text"
      },
      "source": [
        "#### **Load VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf6tYUDUYKvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.applications.VGG16(weights=\"imagenet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBS93Uo9YZvl",
        "colab_type": "text"
      },
      "source": [
        "#### **Model summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJawCdw8Yekc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e9dae56-475c-4fad-b3ac-9c931726a625"
      },
      "source": [
        "'''\n",
        "NOTE :\n",
        "\n",
        "(224,224,3) is input shape on vgg16 model is trained , so we have to pass same shape of input\n",
        "while doing transfer learning  \n",
        "'''\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL0sPff0dM_9",
        "colab_type": "text"
      },
      "source": [
        "We are using vgg-16 as encoder in U-net , so we don't have to train encoder part which saves lot of time , we add decoder layer and trains only those , which is similar to transfer learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLhZ2nFEbskj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "5daeca08-0572-4bd0-dbe9-e29881e20a66"
      },
      "source": [
        "for i,layer in enumerate(model.layers):\n",
        "  print(\"{} \\t {} \\t {} \\t {}\".format(i, layer.name,layer.trainable, layer.output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 \t input_6 \t True \t Tensor(\"input_6:0\", shape=(None, 224, 224, 3), dtype=float32)\n",
            "1 \t block1_conv1 \t True \t Tensor(\"block1_conv1_3/Identity:0\", shape=(None, 224, 224, 64), dtype=float32)\n",
            "2 \t block1_conv2 \t True \t Tensor(\"block1_conv2_3/Identity:0\", shape=(None, 224, 224, 64), dtype=float32)\n",
            "3 \t block1_pool \t True \t Tensor(\"block1_pool_3/Identity:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
            "4 \t block2_conv1 \t True \t Tensor(\"block2_conv1_3/Identity:0\", shape=(None, 112, 112, 128), dtype=float32)\n",
            "5 \t block2_conv2 \t True \t Tensor(\"block2_conv2_3/Identity:0\", shape=(None, 112, 112, 128), dtype=float32)\n",
            "6 \t block2_pool \t True \t Tensor(\"block2_pool_3/Identity:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
            "7 \t block3_conv1 \t True \t Tensor(\"block3_conv1_3/Identity:0\", shape=(None, 56, 56, 256), dtype=float32)\n",
            "8 \t block3_conv2 \t True \t Tensor(\"block3_conv2_3/Identity:0\", shape=(None, 56, 56, 256), dtype=float32)\n",
            "9 \t block3_conv3 \t True \t Tensor(\"block3_conv3_3/Identity:0\", shape=(None, 56, 56, 256), dtype=float32)\n",
            "10 \t block3_pool \t True \t Tensor(\"block3_pool_3/Identity:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
            "11 \t block4_conv1 \t True \t Tensor(\"block4_conv1_3/Identity:0\", shape=(None, 28, 28, 512), dtype=float32)\n",
            "12 \t block4_conv2 \t True \t Tensor(\"block4_conv2_3/Identity:0\", shape=(None, 28, 28, 512), dtype=float32)\n",
            "13 \t block4_conv3 \t True \t Tensor(\"block4_conv3_3/Identity:0\", shape=(None, 28, 28, 512), dtype=float32)\n",
            "14 \t block4_pool \t True \t Tensor(\"block4_pool_3/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
            "15 \t block5_conv1 \t True \t Tensor(\"block5_conv1_3/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
            "16 \t block5_conv2 \t True \t Tensor(\"block5_conv2_3/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
            "17 \t block5_conv3 \t True \t Tensor(\"block5_conv3_3/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
            "18 \t block5_pool \t True \t Tensor(\"block5_pool_3/Identity:0\", shape=(None, 7, 7, 512), dtype=float32)\n",
            "19 \t flatten \t True \t Tensor(\"flatten_3/Identity:0\", shape=(None, 25088), dtype=float32)\n",
            "20 \t fc1 \t True \t Tensor(\"fc1_3/Identity:0\", shape=(None, 4096), dtype=float32)\n",
            "21 \t fc2 \t True \t Tensor(\"fc2_3/Identity:0\", shape=(None, 4096), dtype=float32)\n",
            "22 \t predictions \t True \t Tensor(\"predictions_5/Identity:0\", shape=(None, 1000), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_DTHrawf-UW",
        "colab_type": "text"
      },
      "source": [
        "#### **Freezing layers** <br/>\n",
        "\n",
        "  Before training the network you may want to freeze some of its layers depending upon the task. Once a layer is frozen, its weights are not updated while training.\n",
        "\n",
        "whenever we set this parameter to false \n",
        "it means we are not going to compute gradient \n",
        "for this ,so weights are not going to update for pre-trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Mr_E8Ld5lM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "222fb0ee-aecf-4dae-99a3-bf523fc38a2d"
      },
      "source": [
        "'''\n",
        "we freeze 10 layer from 0 to 9 , by setting layer.trainable = false \n",
        "'''\n",
        "\n",
        "for layer in model.layers[:10]:\n",
        "  layer.trainable = False\n",
        "\n",
        "'''\n",
        "Alternative \n",
        "\n",
        "    for layer in model.layers:\n",
        "      if ['input_3','block1','block2','block3','block4'] in layer.name:\n",
        "        layer.trainable = False\n",
        "\n",
        "'''\n",
        "\n",
        "for i,layer in enumerate(model.layers):\n",
        "  print(\"{} \\t {} \\t {} \\t {}\".format(i, layer.name,layer.trainable, layer.output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 \t input_2 \t False \t Tensor(\"input_2:0\", shape=(None, 224, 224, 3), dtype=float32)\n",
            "1 \t block1_conv1 \t False \t Tensor(\"block1_conv1/Identity:0\", shape=(None, 224, 224, 64), dtype=float32)\n",
            "2 \t block1_conv2 \t False \t Tensor(\"block1_conv2/Identity:0\", shape=(None, 224, 224, 64), dtype=float32)\n",
            "3 \t block1_pool \t False \t Tensor(\"block1_pool/Identity:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
            "4 \t block2_conv1 \t False \t Tensor(\"block2_conv1/Identity:0\", shape=(None, 112, 112, 128), dtype=float32)\n",
            "5 \t block2_conv2 \t False \t Tensor(\"block2_conv2/Identity:0\", shape=(None, 112, 112, 128), dtype=float32)\n",
            "6 \t block2_pool \t False \t Tensor(\"block2_pool/Identity:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
            "7 \t block3_conv1 \t False \t Tensor(\"block3_conv1/Identity:0\", shape=(None, 56, 56, 256), dtype=float32)\n",
            "8 \t block3_conv2 \t False \t Tensor(\"block3_conv2/Identity:0\", shape=(None, 56, 56, 256), dtype=float32)\n",
            "9 \t block3_conv3 \t False \t Tensor(\"block3_conv3/Identity:0\", shape=(None, 56, 56, 256), dtype=float32)\n",
            "10 \t block3_pool \t True \t Tensor(\"block3_pool/Identity:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
            "11 \t block4_conv1 \t True \t Tensor(\"block4_conv1/Identity:0\", shape=(None, 28, 28, 512), dtype=float32)\n",
            "12 \t block4_conv2 \t True \t Tensor(\"block4_conv2/Identity:0\", shape=(None, 28, 28, 512), dtype=float32)\n",
            "13 \t block4_conv3 \t True \t Tensor(\"block4_conv3/Identity:0\", shape=(None, 28, 28, 512), dtype=float32)\n",
            "14 \t block4_pool \t True \t Tensor(\"block4_pool/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
            "15 \t block5_conv1 \t True \t Tensor(\"block5_conv1/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
            "16 \t block5_conv2 \t True \t Tensor(\"block5_conv2/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
            "17 \t block5_conv3 \t True \t Tensor(\"block5_conv3/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
            "18 \t block5_pool \t True \t Tensor(\"block5_pool/Identity:0\", shape=(None, 7, 7, 512), dtype=float32)\n",
            "19 \t flatten \t True \t Tensor(\"flatten/Identity:0\", shape=(None, 25088), dtype=float32)\n",
            "20 \t fc1 \t True \t Tensor(\"fc1/Identity:0\", shape=(None, 4096), dtype=float32)\n",
            "21 \t fc2 \t True \t Tensor(\"fc2/Identity:0\", shape=(None, 4096), dtype=float32)\n",
            "22 \t predictions \t True \t Tensor(\"predictions_1/Identity:0\", shape=(None, 1000), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX1hPAdLgxGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c3b757e3-6d84-4831-8f48-0674835c268e"
      },
      "source": [
        "### We can extract output of one of the conv layer\n",
        "\n",
        "layer_names = ['block1_pool','block2_pool']\n",
        "layer_output = [model.get_layer(layer).output for layer in layer_names]\n",
        "\n",
        "'''\n",
        "  inputs -> Just the input shape let us say (1,224,224,3)\n",
        "  outputs -> would be the output of block1_pool,block2_pool layer\n",
        "  it's not give us actual predicted output because we are passed any image yet but its only give tensor value \n",
        "'''\n",
        "\n",
        "model_practice = tf.keras.Model(inputs = model.input , outputs = layer_output)\n",
        "\n",
        "# Here we are getting 2 outputs because we extract 2 conv layer \n",
        "print(model_practice.output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor 'block1_pool_3/Identity:0' shape=(None, 112, 112, 64) dtype=float32>, <tf.Tensor 'block2_pool_3/Identity:0' shape=(None, 56, 56, 128) dtype=float32>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erQrMBm7Srx0",
        "colab_type": "text"
      },
      "source": [
        "#### **Sanity check**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE_P5qDgiMb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9e6b3806-3fb6-4af6-dfe3-b179a8ef18b8"
      },
      "source": [
        "rand_tensor = tf.random.normal(shape=[1,224,224,3])\n",
        "out_ = model(rand_tensor)\n",
        "'''\n",
        "We receive output from block1_pool_1\n",
        "Relu = max(0,x) \n",
        "thier we have relu : 0   if value<0\n",
        "                     x   if value>0  \n",
        "we feed a random input tensor of size (224,224,3) , here 1 indicate 1 sample\n",
        "'''\n",
        "print(tf.reduce_sum(tf.cast(out_[0]>0,tf.float32)))\n",
        "print(tf.reduce_sum(tf.cast(out_[0]<0,tf.float32)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1000.0, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGn1gxKHrCV3",
        "colab_type": "text"
      },
      "source": [
        "#### **How to add layers** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv9CwFonqikv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "\n",
        "model = tf.keras.applications.VGG16(weights=\"imagenet\")\n",
        "model = tf.keras.Model(inputs= model.input , outputs=model.get_layer('block4_pool').output)\n",
        "\n",
        "### Extract output from the block4_pool\n",
        "'''\n",
        "Another way\n",
        "x = model(model.input)\n",
        "'''\n",
        "x = model.output \n",
        "\n",
        "x = Conv2D(filters=64,kernel_size=(3,3),activation='relu',name='extended_1')(x)\n",
        "x = Conv2D(filters=64,kernel_size=(3,3),name='extended_2')(x)\n",
        "x = BatchNormalization(name = 'BN_')(x)\n",
        "x = Conv2D(filters=64,kernel_size=(3,3),use_bias=True,name='extended_3')(x)\n",
        "\n",
        "model_new = tf.keras.Model(inputs = model.input,outputs = x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WuTxFKjtmMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "ea8a3296-5893-43a2-ecd9-c6f5e3aa9394"
      },
      "source": [
        "model_new.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "extended_1 (Conv2D)          (None, 12, 12, 64)        294976    \n",
            "_________________________________________________________________\n",
            "extended_2 (Conv2D)          (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "BN_ (BatchNormalization)     (None, 10, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "extended_3 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 8,004,352\n",
            "Trainable params: 8,004,224\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaLNbJXUFCBL",
        "colab_type": "text"
      },
      "source": [
        "### **Embedding vgg16 as encoder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-VNuDDpGGUs",
        "colab_type": "text"
      },
      "source": [
        "<p align=\"center\"><img src=\"https://www.pyimagesearch.com/wp-content/uploads/2017/03/imagenet_vggnet_table1.png\" width=\"50%\"/>\n",
        "\n",
        "Here we have 5 set of convolutional unit (include conv + pool layer) and then 3 fully connected layer are attached at the end.\n",
        "\n",
        "we extract last conv layer from each unit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yOM45SiFBcp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "83a16783-92ec-448f-d5af-86393d0ea3e7"
      },
      "source": [
        "\n",
        "model = tf.keras.applications.VGG16(weights=\"imagenet\")\n",
        "\n",
        "layers_name = ['block1_conv2','block2_conv2','block3_conv2','block4_conv2','block5_conv2']\n",
        "layers_outputs = [model.get_layer(name).output for name in layers_name]\n",
        "\n",
        "model = tf.keras.Model(inputs = model.input , outputs = layers_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "=================================================================\n",
            "Total params: 12,354,880\n",
            "Trainable params: 12,354,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzrKE-gQM3pA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "b4e120a9-61b2-4f42-9bf0-62fdac0473f4"
      },
      "source": [
        "for i,layer in enumerate(model.layers):\n",
        "  layer.trainable = False\n",
        "  print(\"{} \\t {} \\t {} \\t {}\".format(i, layer.name,layer.trainable, layer.output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 \t input_8 \t False \t Tensor(\"input_8:0\", shape=(None, 224, 224, 3), dtype=float32)\n",
            "1 \t block1_conv1 \t False \t Tensor(\"block1_conv1_5/Identity:0\", shape=(None, 224, 224, 64), dtype=float32)\n",
            "2 \t block1_conv2 \t False \t Tensor(\"block1_conv2_5/Identity:0\", shape=(None, 224, 224, 64), dtype=float32)\n",
            "3 \t block1_pool \t False \t Tensor(\"block1_pool_5/Identity:0\", shape=(None, 112, 112, 64), dtype=float32)\n",
            "4 \t block2_conv1 \t False \t Tensor(\"block2_conv1_5/Identity:0\", shape=(None, 112, 112, 128), dtype=float32)\n",
            "5 \t block2_conv2 \t False \t Tensor(\"block2_conv2_5/Identity:0\", shape=(None, 112, 112, 128), dtype=float32)\n",
            "6 \t block2_pool \t False \t Tensor(\"block2_pool_5/Identity:0\", shape=(None, 56, 56, 128), dtype=float32)\n",
            "7 \t block3_conv1 \t False \t Tensor(\"block3_conv1_5/Identity:0\", shape=(None, 56, 56, 256), dtype=float32)\n",
            "8 \t block3_conv2 \t False \t Tensor(\"block3_conv2_5/Identity:0\", shape=(None, 56, 56, 256), dtype=float32)\n",
            "9 \t block3_conv3 \t False \t Tensor(\"block3_conv3_5/Identity:0\", shape=(None, 56, 56, 256), dtype=float32)\n",
            "10 \t block3_pool \t False \t Tensor(\"block3_pool_5/Identity:0\", shape=(None, 28, 28, 256), dtype=float32)\n",
            "11 \t block4_conv1 \t False \t Tensor(\"block4_conv1_5/Identity:0\", shape=(None, 28, 28, 512), dtype=float32)\n",
            "12 \t block4_conv2 \t False \t Tensor(\"block4_conv2_5/Identity:0\", shape=(None, 28, 28, 512), dtype=float32)\n",
            "13 \t block4_conv3 \t False \t Tensor(\"block4_conv3_5/Identity:0\", shape=(None, 28, 28, 512), dtype=float32)\n",
            "14 \t block4_pool \t False \t Tensor(\"block4_pool_5/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
            "15 \t block5_conv1 \t False \t Tensor(\"block5_conv1_5/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n",
            "16 \t block5_conv2 \t False \t Tensor(\"block5_conv2_5/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9eJrdx4MBrF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "7b2c1720-a3c6-4529-bb74-28df0ac3cc72"
      },
      "source": [
        "x = model.output\n",
        "\n",
        "for i in x:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"block1_conv2_5/Identity:0\", shape=(None, 224, 224, 64), dtype=float32)\n",
            "Tensor(\"block2_conv2_5/Identity:0\", shape=(None, 112, 112, 128), dtype=float32)\n",
            "Tensor(\"block3_conv2_5/Identity:0\", shape=(None, 56, 56, 256), dtype=float32)\n",
            "Tensor(\"block4_conv2_5/Identity:0\", shape=(None, 28, 28, 512), dtype=float32)\n",
            "Tensor(\"block5_conv2_5/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXg11SjLPF6l",
        "colab_type": "text"
      },
      "source": [
        "We add encoder part of vgg16 model and concatenate latent or bottenleck layer (i.e. between encoder and decoder) and decoder layer to get a representation similar to u-net architecture.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://www.pyimagesearch.com/wp-content/uploads/2020/02/keras_autoencoder_arch_flow.png\" width=\"50%\"/>\n",
        "\n",
        "Now we have \n",
        "\n",
        "input -> 5 Block of encoder -> 1 Latent layer -> 5 Block of decoder -> output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW0efv-2x8AO",
        "colab_type": "text"
      },
      "source": [
        "### **Concatenation of encoder with decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sJju1qZtzbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# -- Keras Functional API -- #\n",
        "# -- UNet Implementation -- #\n",
        "\n",
        "# If you want to know more about why we are using `he_normal`: \n",
        "# https://stats.stackexchange.com/questions/319323/whats-the-difference-between-variance-scaling-initializer-and-xavier-initialize/319849#319849  \n",
        "# Or the excelent fastai course: \n",
        "# https://github.com/fastai/course-v3/blob/master/nbs/dl2/02b_initializing.ipynb\n",
        "\n",
        "initializer = 'he_normal'\n",
        "'''\n",
        "Padding = 'same': means input size and output size would be same , so thier is no reduction in size.\n",
        "so it preserve the size. \n",
        "if we use kernel (3x3) then padding = 1 ,  \n",
        "if we use kernel (5x5) then padding = 2 and so on\n",
        "\n",
        "when we use padding='valid' : then thier is reduction in size\n",
        "'''\n",
        "\n",
        "# -- Encoder -- #\n",
        "'''\n",
        "5 block of encoder : x[0],.......x[4]\n",
        "'''\n",
        "x = model.output\n",
        "# -- Encoder -- #\n",
        "\n",
        "# -----Latent layer------ #\n",
        "maxpool = MaxPooling2D(pool_size=(2, 2))(x[4])\n",
        "conv = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(maxpool)\n",
        "conv = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv)\n",
        "# ----------- #\n",
        "\n",
        "'''\n",
        "first we upsample then we do concatenation.\n",
        "\n",
        "Concatenation \n",
        "\n",
        "one input of size = (224,224,3)\n",
        "another input of size = (224,224,3)\n",
        "concatenation of both result to = (224,224,6)\n",
        "'''\n",
        "\n",
        "# -- Dencoder -- #\n",
        "\n",
        "# Block decoder 1\n",
        "'''\n",
        "when upsampling size=(2,2) means when their is input size=2x2 which gets \n",
        "transformed to output size=4x4 by using some interpolation technique \n",
        "'''\n",
        "up_dec_1 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv))\n",
        "merge_dec_1 = concatenate([x[4], up_dec_1], axis = 3)\n",
        "conv_dec_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_1)\n",
        "conv_dec_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_1)\n",
        "\n",
        "# Block decoder 2\n",
        "up_dec_2 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv_dec_1))\n",
        "merge_dec_2 = concatenate([x[3], up_dec_2], axis = 3)\n",
        "conv_dec_2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_2)\n",
        "conv_dec_2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_2)\n",
        "\n",
        "# Block decoder 3\n",
        "up_dec_3 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv_dec_2))\n",
        "merge_dec_3 = concatenate([x[2], up_dec_3], axis = 3)\n",
        "conv_dec_3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_3)\n",
        "conv_dec_3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_3)\n",
        "\n",
        "# Block decoder 4\n",
        "up_dec_4 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv_dec_3))\n",
        "merge_dec_4 = concatenate([x[1], up_dec_4], axis = 3)\n",
        "conv_dec_4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_4)\n",
        "conv_dec_4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_4)\n",
        "conv_dec_4 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_4)\n",
        "\n",
        "# Block decoder 4\n",
        "up_dec_5 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv_dec_4))\n",
        "merge_dec_5 = concatenate([x[0], up_dec_5], axis = 3)\n",
        "conv_dec_5 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_5)\n",
        "conv_dec_5 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_5)\n",
        "conv_dec_5 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_5)\n",
        "# -- Dencoder -- #\n",
        "\n",
        "'''\n",
        "Here we are commented the output part because we are not going to pass any input in the form \n",
        "of image , we are just defining the architecture.\n",
        "'''\n",
        "# -----Output----#\n",
        "# output = Conv2D(N_CLASSES, 1, activation = 'softmax')(conv_dec_5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e49-MO-wptlj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e36db99-7e01-4e02-b8f8-3e94f08e2735"
      },
      "source": [
        "'''\n",
        "Here we can both \"encoder of vgg16 + decoder\" get concatenated together.  \n",
        "'''\n",
        "\n",
        "model = tf.keras.Model(inputs= model.input , outputs = conv_dec_5)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 7, 7, 512)    0           block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 7, 7, 1024)   4719616     max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 7, 7, 1024)   9438208     conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 14, 14, 1024) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 14, 14, 512)  2097664     up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 14, 14, 1024) 0           block5_conv2[0][0]               \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 14, 14, 512)  4719104     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 14, 14, 512)  2359808     conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 512)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 256)  524544      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 28, 28, 768)  0           block4_conv2[0][0]               \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 256)  1769728     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 256)  590080      conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 256)  0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 56, 56, 128)  131200      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 56, 56, 384)  0           block3_conv2[0][0]               \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 56, 56, 128)  442496      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 128 0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 112, 112, 64) 32832       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 112, 112, 192 0           block2_conv2[0][0]               \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 112, 112, 64) 110656      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 112, 112, 64) 36928       conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 112, 112, 2)  1154        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 2)  0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 224, 224, 64) 576         up_sampling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 224, 224, 128 0           block1_conv2[0][0]               \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 224, 224, 64) 73792       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 224, 224, 64) 36928       conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 224, 224, 2)  1154        conv2d_17[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 39,588,932\n",
            "Trainable params: 27,234,052\n",
            "Non-trainable params: 12,354,880\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OLI8Via0EPA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### **NOTE :**\n",
        "\n",
        "**Question** :As pre-trained model learned the weights based on the perticular input size so it would be problematic , if we pass different size of image as input in pre-trained model ?\n",
        "\n",
        "**Answer** : The only problem with pre-trained model with different image is \n",
        "that when we use fully connected or dense layer at the end. \n",
        "Because convolution layer doesn't care about size , it will just reduce the size based on the kernel .  \n",
        "\n",
        "so when we remove fully connected layer from pre-trained model , so then thier is no problem.\n",
        "\n",
        "let us suppose are vgg16 trained on input size (224,224,3) ,we get output (7,7,512) from last conv layer then we flatten the output and passed to FC (Fully connected) layer we get some output.\n",
        "\n",
        "but when we pass input size (448,448,3) ,we get output (14,14,512) from last conv layer then we flatten the output and passed to FC (Fully connected) layer we get we get error because now the size of fc layer gets changed.\n",
        "\n",
        "so in segmentation we don't get any problem related to input size because we are removing fc layer and only use conv layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB-wqi-vw-28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}